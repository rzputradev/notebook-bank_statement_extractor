{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import difflib\n",
    "from rapidfuzz import fuzz\n",
    "from helper import load_json_file, save_json_file, normalize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_setting_by_id(statement_id, key=None):\n",
    "    try:\n",
    "        settings = load_json_file(\"database/extractor_settings.json\")\n",
    "        setting = next((setting for setting in settings if setting[\"id\"] == statement_id), None)\n",
    "        if not setting:\n",
    "            return None\n",
    "        if key is None:\n",
    "            return setting\n",
    "        else:\n",
    "            return setting.get(key)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statement_id(data):\n",
    "    normalized_data = normalize_text(data)\n",
    "    settings = load_json_file(\"database/extractor_settings.json\")\n",
    "    \n",
    "    ranking = []\n",
    "    \n",
    "    for setting in settings:\n",
    "        total_word_count = sum(len(keyword.split()) for keyword in setting['keyword'])\n",
    "        \n",
    "        scores = [fuzz.partial_ratio(normalize_text(keyword), normalized_data)\n",
    "                  for keyword in setting['keyword'] if fuzz.partial_ratio(normalize_text(keyword), normalized_data) > 80]  \n",
    "        \n",
    "        if scores:\n",
    "            final_score = sum(scores) * total_word_count\n",
    "            ranking.append({\n",
    "                \"setting\": setting,\n",
    "                \"final_score\": final_score\n",
    "            })\n",
    "\n",
    "    if not ranking:\n",
    "        return None\n",
    "    \n",
    "    return max(ranking, key=lambda x: x[\"final_score\"])[\"setting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match_words(string, substring, threshold=0.9, window_variation=1):\n",
    "    string_words = string\n",
    "    substring_words = substring\n",
    "    len_string = len(string_words)\n",
    "    len_sub = len(substring_words)\n",
    "    \n",
    "    substring_space = ' '.join(substring_words)\n",
    "    substring_concat = ''.join(substring_words)\n",
    "    \n",
    "    best_ratio = 0\n",
    "    best_start = None\n",
    "    best_end = None\n",
    "\n",
    "    min_window = max(1, len_sub - window_variation)\n",
    "    max_window = len_sub + window_variation\n",
    "    \n",
    "    for window_size in range(min_window, max_window + 1):\n",
    "        for start in range(len_string - window_size + 1):\n",
    "            end = start + window_size\n",
    "            candidate_words = string_words[start:end]\n",
    "            candidate_space = ' '.join(candidate_words)\n",
    "            candidate_concat = ''.join(candidate_words)\n",
    "\n",
    "            ratio_space = difflib.SequenceMatcher(None, candidate_space, substring_space).ratio()\n",
    "            ratio_concat = difflib.SequenceMatcher(None, candidate_concat, substring_concat).ratio()\n",
    "            ratio = max(ratio_space, ratio_concat)\n",
    "            \n",
    "            if ratio > best_ratio:\n",
    "                best_ratio = ratio\n",
    "                best_start = start\n",
    "                best_end = end - 1\n",
    "                \n",
    "    if best_start is not None and best_ratio >= threshold:\n",
    "        return best_start, best_end, best_ratio\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_contents(data):\n",
    "    statement_id = data['statement_id']\n",
    "    dimensions = data['dimensions']\n",
    "    page_id = data['page_id']\n",
    "\n",
    "    if statement_id is None:\n",
    "        return None\n",
    "   \n",
    "    upper_devider = [normalize_text(word) for value in get_setting_by_id(statement_id, \"column_name\").values() for word in value.split()]\n",
    "    lower_devider = [normalize_text(word) for word in get_setting_by_id(statement_id, \"lower_limit\").split()]\n",
    "    combined_devider = upper_devider + lower_devider\n",
    "    \n",
    "    matched_keywords = []\n",
    "\n",
    "    for word in data['words']:\n",
    "        word_value_normalized = normalize_text(word['value'])\n",
    "        if any(fuzz.partial_ratio(keyword, word_value_normalized) > 80 for keyword in combined_devider):\n",
    "            matched_keywords.append(word)\n",
    "\n",
    "    words_list = [normalize_text(word['value']) for word in matched_keywords]\n",
    "\n",
    "    upper_match = find_best_match_words(words_list, upper_devider)\n",
    "    lower_match = find_best_match_words(words_list, lower_devider)\n",
    "\n",
    "    limit = {}\n",
    "    result = {}\n",
    "    header = None\n",
    "\n",
    "    if upper_match is not None:\n",
    "        start, end, ratio = upper_match\n",
    "        upper_words = matched_keywords[start:end+1]\n",
    "        lowest_y_end = max(item['geometry'][1][1] for item in upper_words)\n",
    "        limit['upper'] = lowest_y_end\n",
    "        header = upper_words\n",
    "\n",
    "    else:\n",
    "        limit['upper'] = None\n",
    "\n",
    "    if lower_match is not None:\n",
    "        start, end, ratio = lower_match\n",
    "        lower_words = matched_keywords[start:end+1]\n",
    "        highest_y_end = min(item['geometry'][1][1] for item in lower_words)\n",
    "        limit['lower'] = highest_y_end\n",
    "    else:\n",
    "        limit['lower'] = None\n",
    "\n",
    "    filered_words = []\n",
    "    for word in data['words']:\n",
    "        word_y_end = word['geometry'][1][1] \n",
    "        if (limit['upper'] is None or word_y_end > limit['upper']) and \\\n",
    "        (limit['lower'] is None or word_y_end < limit['lower']):\n",
    "            filered_words.append(word)\n",
    "\n",
    "    result = {\n",
    "        \"page_id\": page_id,\n",
    "        \"statement_id\": statement_id,\n",
    "        \"dimension\": dimensions,\n",
    "        \"header\": header,\n",
    "        \"words\": filered_words\n",
    "    }\n",
    "\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_json(data):\n",
    "    result = []\n",
    "    default_statement = get_setting_by_id(0)\n",
    "    previous_statement = None\n",
    "\n",
    "    for page in data['pages']:\n",
    "        page_id = page['page_idx']\n",
    "        dimensions = page['dimensions']\n",
    "\n",
    "        page_words = [\n",
    "            word\n",
    "            for block in page['blocks']\n",
    "            for line in block['lines']\n",
    "            for word in line['words']\n",
    "        ]\n",
    "\n",
    "        combined_words = [\n",
    "            ''.join(normalize_text(word['value']).split())\n",
    "            for word in page_words[:20]\n",
    "        ]\n",
    "        combined_words_text = ' '.join(combined_words)\n",
    "\n",
    "        statement = get_statement_id(combined_words_text)\n",
    "\n",
    "        if statement is not None:\n",
    "            statement_id = statement['id']\n",
    "            previous_statement = statement \n",
    "        else:\n",
    "            statement_id = None\n",
    "\n",
    "        if statement_id is None:\n",
    "            if (previous_statement is not None and\n",
    "                previous_statement['parameter']['statement_title'] == False):\n",
    "                statement_id = previous_statement['id']\n",
    "            else:\n",
    "                statement_id = default_statement['id']\n",
    "\n",
    "        word_entries = [\n",
    "            {\n",
    "                \"value\": word['value'],\n",
    "                \"confidence\": word['confidence'],\n",
    "                \"geometry\": word['geometry']\n",
    "            }\n",
    "            for word in page_words\n",
    "        ]\n",
    "\n",
    "        normalized_page = {\n",
    "            \"page_id\": page_id,\n",
    "            \"dimensions\": dimensions,\n",
    "            \"statement_id\": statement_id,\n",
    "            \"words\": word_entries\n",
    "        }\n",
    "\n",
    "        content = get_table_contents(normalized_page)\n",
    "\n",
    "        result.append(content)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_normalize_json(file_path, output_path):\n",
    "   if not os.path.exists(file_path):\n",
    "      raise Exception(\"File not found\")\n",
    "   \n",
    "   if not os.path.isdir(output_path):\n",
    "      raise Exception(\"Output path is not a directory\")\n",
    "\n",
    "   if not os.path.exists(output_path):\n",
    "      os.makedirs(output_path)\n",
    "\n",
    "   try:\n",
    "      output_path = os.path.join(output_path, os.path.basename(file_path))\n",
    "      data = load_json_file(file_path)\n",
    "      result = normalize_json(data)\n",
    "      save_json_file(output_path, result)\n",
    "   except Exception as e:\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mandiri - Account Statement Report\n",
    "process_normalize_json(\"sample/scanned/mandiri-account_statement_report.json\", \"sample/normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manual_ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
